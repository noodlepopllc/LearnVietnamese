{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/noodlepopllc/LearnVietnamese/blob/main/Colab/Translate.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##**Imports**\n",
        "\n",
        "First import models needed\n",
        " - torch https://pytorch.org/\n",
        " - transformers https://github.com/huggingface/transformers\n",
        "\n",
        " The model we are going to be using is based on T5 https://huggingface.co/docs/transformers/model_doc/t5"
      ],
      "metadata": {
        "id": "UYQa6KJTn-eH"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "JDhlHQGI2DHa"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##**Get Device**\n",
        "\n",
        "Check to see if cuda is available for hardware acceleration otherwise use cpu for inferencing"
      ],
      "metadata": {
        "id": "ULooGXJeozf6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "device = \"cuda:0\" if torch.cuda.is_available() else \"cpu\"\n",
        "print(device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TqvOqWW87jto",
        "outputId": "5a86835c-4929-40f9-8b93-035ef2040c5a"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cpu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##**Load the Model**\n",
        "\n",
        "The model we are using comes from VietAI this is an open source english to vietnamese t5 translator, it is quite fast and runs well even on cpu\n",
        "\n",
        "https://huggingface.co/VietAI/envit5-translation\n",
        "\n"
      ],
      "metadata": {
        "id": "UvIk_Ia_pTRb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_name = \"VietAI/envit5-translation\"\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "model = AutoModelForSeq2SeqLM.from_pretrained(model_name).to(device)"
      ],
      "metadata": {
        "id": "kIfN02fL747N"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##**Translation**\n",
        "\n",
        "First need a list of inputs, this model can handle both English to Vietnamese and Vietnamese to English. Each item in the list must start with either vi: or en: to notify the model of the input language.\n",
        "\n",
        "Next the tokenizer will take the inputs and convert them into pytorch format and copy them to the device. The tokens must be in the same memory as the model. Finally the oposite has to take place must take the output tokens and covert them back into words. The output generated is same as the input, prepended with vi: or en: depending on language.\n"
      ],
      "metadata": {
        "id": "IfRMo1CSqswr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##**Example of Vietnamese to English**"
      ],
      "metadata": {
        "id": "_6ljZxUPsPx3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "inputs = ['vi: Xin chào thế giới']\n",
        "outputs = model.generate(tokenizer(inputs, return_tensors=\"pt\", padding=True).input_ids.to(device), max_length=512)\n",
        "print([output for output in tokenizer.batch_decode(outputs, skip_special_tokens=True)])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uLOXUD11_mH3",
        "outputId": "8c1288a7-5f4f-4861-8f15-5aece112eaf3"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['en: Hello world']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##**Example of English to Vietnamese**"
      ],
      "metadata": {
        "id": "zE3-0bcOsH7O"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "inputs = [\"en: Hello world\"]\n",
        "outputs = model.generate(tokenizer(inputs, return_tensors=\"pt\", padding=True).input_ids.to(device), max_length=512)\n",
        "print([output for output in tokenizer.batch_decode(outputs, skip_special_tokens=True)])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qzohd8T1_W7A",
        "outputId": "3768f587-5159-41c0-ae6d-1de19856d7e6"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['vi: Xin chào thế giới']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##**Free Memory**\n",
        "\n",
        "Import garbage collector, delete model, call garbage collector to free memory and empty cuda cache if in use\n",
        "\n",
        "Not clear if model.cpu() is actually necessary"
      ],
      "metadata": {
        "id": "owLWUR2tbsXv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import gc\n",
        "\n",
        "model.cpu()\n",
        "del model\n",
        "del tokenizer\n",
        "gc.collect()\n",
        "torch.cuda.empty_cache()"
      ],
      "metadata": {
        "id": "VAYMnjxIakUd"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Creating UI Elements\n",
        "\n",
        "Next we are going to create a class to make the model a bit easier to use without requiring the rerunning of the cell\n"
      ],
      "metadata": {
        "id": "rldgWmVCCQ30"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import ipywidgets as widgets\n",
        "from ipywidgets import Layout\n",
        "\n",
        "class VietTranslate(object):\n",
        "    def __init__(self):\n",
        "        self.device = \"cuda:0\" if torch.cuda.is_available() else \"cpu\"\n",
        "        self.model_name = \"VietAI/envit5-translation\"\n",
        "        self.tokenizer = AutoTokenizer.from_pretrained(self.model_name)\n",
        "        self.model = AutoModelForSeq2SeqLM.from_pretrained(self.model_name)\\\n",
        "            .to(self.device)\n",
        "\n",
        "    def display(self,description='',button_description='Translate',text=''):\n",
        "        self.textarea = widgets.Textarea(\n",
        "            value=text,\n",
        "            description= f'{description}:',\n",
        "            disabled=False,\n",
        "            layout=Layout(width='80%', height=\"100px\"))\n",
        "        self.output = widgets.Output(layout=Layout(width='80%', height='100px'))\n",
        "        self.button = widgets.Button(description=button_description)\n",
        "        self.button.on_click(self.button_pressed)\n",
        "        display(self.textarea,self.button,self.output)\n",
        "\n",
        "    def translate(self, t):\n",
        "        inputs = [x for x in t.split('\\n') if len(x) > 0]\n",
        "        outputs = self.model.generate(self.tokenizer(inputs,\n",
        "            return_tensors=\"pt\", padding=True).input_ids.to(self.device),\n",
        "            max_length=512)\n",
        "        return [output for output in self.tokenizer.batch_decode(outputs,\n",
        "                skip_special_tokens=True)]\n",
        "\n",
        "    def button_pressed(self, b):\n",
        "        self.output.clear_output()\n",
        "        with self.output:\n",
        "            for line in self.translate(self.textarea.value):\n",
        "                print(line)\n"
      ],
      "metadata": {
        "id": "PXjD_diFCeQb"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## You can change the text below in the box and hit the button to get the translation instead of rerunning the cells"
      ],
      "metadata": {
        "id": "vPde9k50JLvu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "translator = VietTranslate()\n",
        "translator.display('Vietnamese','English',text='''\n",
        "vi: VietAI là tổ chức phi lợi nhuận với sứ mệnh ươm mầm tài năng về trí tuệ nhân tạo và xây dựng một cộng đồng các chuyên gia trong lĩnh vực trí tuệ nhân tạo đẳng cấp quốc tế tại Việt Nam.\n",
        "\n",
        "vi: Theo báo cáo mới nhất của Linkedin về danh sách việc làm triển vọng với mức lương hấp dẫn năm 2020, các chức danh công việc liên quan đến AI như Chuyên gia AI (Artificial Intelligence Specialist), Kỹ sư ML (Machine Learning Engineer) đều xếp thứ hạng cao.\n",
        "''')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 253,
          "referenced_widgets": [
            "ea00f43112c94738b3046d3c9a9da959",
            "0af2c88efba64ea59fb4fb6cb0130df9",
            "64ccac3c9918412084d342527d52133b",
            "3ff6af9acbfb467d827c33f1ae9648ac",
            "b129af4842b249ce8bde42ae876a383e",
            "e47f63c701ca409bad2359955486450d",
            "3c76570ecfb94beea951c323c7bcbc40",
            "e080d2af77084b55a7e128feabbadbe0"
          ]
        },
        "id": "w2GuoWeRDaZf",
        "outputId": "99a2cc01-05b9-4061-e36b-46b4b8211012"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Textarea(value='\\nvi: VietAI là tổ chức phi lợi nhuận với sứ mệnh ươm mầm tài năng về trí tuệ nhân tạo và xây …"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "ea00f43112c94738b3046d3c9a9da959"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Button(description='English', style=ButtonStyle())"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "3ff6af9acbfb467d827c33f1ae9648ac"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Output(layout=Layout(height='100px', width='80%'))"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "3c76570ecfb94beea951c323c7bcbc40"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "translator2 = VietTranslate()\n",
        "translator2.display('English','Vietnamese',text= '''\n",
        "en: Our teams aspire to make discoveries that impact everyone, and core to our approach is sharing our research and tools to fuel progress in the field.\"\n",
        "\n",
        "en: We're on a journey to advance and democratize artificial intelligence through open source and open science.\n",
        "''')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 253,
          "referenced_widgets": [
            "fbb2753ec27d44dd8b31e77fea105325",
            "eac1da07d44c40b090f1b5ade7c83a97",
            "56c9e4dbdf874b328e14303e3a9ee107",
            "cd0102a5eaa840df9df01c4755488dd5",
            "c183e7cd1a564780b728c6db38b37abe",
            "1b3daeadf59c4b8a87e95064d8969584",
            "6a9a32b4e44e47e6baa4c5eb98a5a07a",
            "ade8f2dde7b040e8b9e917a8bc96e775"
          ]
        },
        "id": "unP72BhIDf1P",
        "outputId": "b13207c8-1005-44b3-d760-43749b3ffc48"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Textarea(value='\\nen: Our teams aspire to make discoveries that impact everyone, and core to our approach is s…"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "fbb2753ec27d44dd8b31e77fea105325"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Button(description='Vietnamese', style=ButtonStyle())"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "cd0102a5eaa840df9df01c4755488dd5"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Output(layout=Layout(height='100px', width='80%'))"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "6a9a32b4e44e47e6baa4c5eb98a5a07a"
            }
          },
          "metadata": {}
        }
      ]
    }
  ]
}
