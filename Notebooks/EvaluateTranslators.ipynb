{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cb207b7b-494f-4a08-9922-199167fa8e2a",
   "metadata": {},
   "source": [
    "## All the imports we need for translations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "58e9ac96-a665-4440-959f-8ad8640e9483",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM, T5ForConditionalGeneration, T5Tokenizer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0038a9f8-d61d-4919-a662-df555a8b65ca",
   "metadata": {},
   "source": [
    "## The first 5 paragraphs from Alice in Wonderland\n",
    "\n",
    "Source is project guhtenberg https://www.gutenberg.org/cache/epub/11/pg11.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "49f5eaad-54c5-4905-a8cf-dd190a631e3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "englishtexts = ['''Alice was beginning to get very tired of sitting by her sister on the\n",
    "bank, and of having nothing to do: once or twice she had peeped into\n",
    "the book her sister was reading, but it had no pictures or\n",
    "conversations in it, “and what is the use of a book,” thought Alice\n",
    "“without pictures or conversations?”\n",
    "''','''So she was considering in her own mind (as well as she could, for the\n",
    "hot day made her feel very sleepy and stupid), whether the pleasure of\n",
    "making a daisy-chain would be worth the trouble of getting up and\n",
    "picking the daisies, when suddenly a White Rabbit with pink eyes ran\n",
    "close by her.\n",
    "''','''There was nothing so _very_ remarkable in that; nor did Alice think it\n",
    "so _very_ much out of the way to hear the Rabbit say to itself, “Oh\n",
    "dear! Oh dear! I shall be late!” (when she thought it over afterwards,\n",
    "it occurred to her that she ought to have wondered at this, but at the\n",
    "time it all seemed quite natural); but when the Rabbit actually _took a\n",
    "watch out of its waistcoat-pocket_, and looked at it, and then hurried\n",
    "on, Alice started to her feet, for it flashed across her mind that she\n",
    "had never before seen a rabbit with either a waistcoat-pocket, or a\n",
    "watch to take out of it, and burning with curiosity, she ran across the\n",
    "field after it, and fortunately was just in time to see it pop down a\n",
    "large rabbit-hole under the hedge.\n",
    "''','''In another moment down went Alice after it, never once considering how\n",
    "in the world she was to get out again.\n",
    "''','''The rabbit-hole went straight on like a tunnel for some way, and then\n",
    "dipped suddenly down, so suddenly that Alice had not a moment to think\n",
    "about stopping herself before she found herself falling down a very\n",
    "deep well.\n",
    "''','''Either the well was very deep, or she fell very slowly, for she had\n",
    "plenty of time as she went down to look about her and to wonder what\n",
    "was going to happen next. First, she tried to look down and make out\n",
    "what she was coming to, but it was too dark to see anything; then she\n",
    "looked at the sides of the well, and noticed that they were filled with\n",
    "cupboards and book-shelves; here and there she saw maps and pictures\n",
    "hung upon pegs. She took down a jar from one of the shelves as she\n",
    "passed; it was labelled “ORANGE MARMALADE”, but to her great\n",
    "disappointment it was empty: she did not like to drop the jar for fear\n",
    "of killing somebody underneath, so managed to put it into one of the\n",
    "cupboards as she fell past it.''']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cc8bd62-5891-4398-b90c-3fa78968baa5",
   "metadata": {},
   "source": [
    "## Pick device if using cuda or not and display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5d58fbcd-4eed-4d51-b257-4a00a9d37cc6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "device = \"cuda:0\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "902fc70e-eb09-4704-ac40-13b74377941a",
   "metadata": {},
   "source": [
    "## Load models for translation\n",
    "\n",
    "The models total take between 6 and 8 gigs, should work on cards with 8 gigs of ram also runs fine on cpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f191cd18-c522-494f-b8d7-d349e1fc2862",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"VietAI/envit5-translation\"\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(model_name).to(device) \n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f0287dd5-9056-4b6d-9137-19117e1eaed8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are using the default legacy behaviour of the <class 'transformers.models.t5.tokenization_t5.T5Tokenizer'>. This is expected, and simply means that the `legacy` (previous) behavior will be used so nothing changes for you. If you want to use the new behaviour, set `legacy=False`. This should only be set if you understand what it means, and thoroughly read the reason why this was added as explained in https://github.com/huggingface/transformers/pull/24565\n"
     ]
    }
   ],
   "source": [
    "model_name2 = \"NlpHUST/t5-en-vi-small\"\n",
    "model2 = T5ForConditionalGeneration.from_pretrained(model_name2).to(device)\n",
    "tokenizer2 = T5Tokenizer.from_pretrained(model_name2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3a958138-4e8e-4021-bd32-3f0584eecd95",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name3 = \"NlpHUST/t5-vi-en-small\"\n",
    "model3 = T5ForConditionalGeneration.from_pretrained(model_name3).to(device)\n",
    "tokenizer3 = T5Tokenizer.from_pretrained(model_name3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b5eca387-66fc-4048-8927-08ec57aa734e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name4 = \"vinai/vinai-translate-en2vi-v2\"\n",
    "tokenizer4 = AutoTokenizer.from_pretrained(model_name4, src_lang=\"en_XX\")\n",
    "model4 = AutoModelForSeq2SeqLM.from_pretrained(model_name4).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a3839fdc-db98-4a82-84f1-288329d78013",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name5 = \"vinai/vinai-translate-vi2en-v2\"\n",
    "tokenizer5 = AutoTokenizer.from_pretrained(model_name5, src_lang=\"vi_VN\")\n",
    "model5 = AutoModelForSeq2SeqLM.from_pretrained(model_name5).to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f50a4b2-c895-4a0f-838f-178844478a9e",
   "metadata": {},
   "source": [
    "## Dictionary below will hold the translations for each of the models\n",
    "\n",
    "Code below simply gets all the English text and converts to Vietnamese, the translations are indexed by model names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4518b3c6-1778-407e-a583-5701594a810d",
   "metadata": {},
   "outputs": [],
   "source": [
    "translated_outputs = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4c2539f9-9e16-4893-8f6d-ad57fe7086ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VietAI/envit5-translation\n"
     ]
    }
   ],
   "source": [
    "print(model_name)\n",
    "translated_outputs[model_name] = []\n",
    "for englishtext in englishtexts:\n",
    "    inputs = [f\"en: {englishtext}\"]\n",
    "    outputs = model.generate(tokenizer(inputs, return_tensors=\"pt\", padding=True).input_ids.to(device), max_length=512)\n",
    "    output = [output for output in tokenizer.batch_decode(outputs, skip_special_tokens=True)][0].split('vi: ')[1]\n",
    "    translated_outputs[model_name].append(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3aaea792-afa8-4308-a91e-619e0ee66756",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NlpHUST/t5-en-vi-small\n"
     ]
    }
   ],
   "source": [
    "print(model_name2)\n",
    "translated_outputs[model_name2] = []\n",
    "for englishtext in englishtexts:\n",
    "    tokenized_text = tokenizer2.encode(englishtext, return_tensors=\"pt\").to(device)\n",
    "    model2.eval()\n",
    "    summary_ids = model2.generate(\n",
    "                        tokenized_text,\n",
    "                        max_length=512,\n",
    "                        num_beams=5,\n",
    "                        repetition_penalty=2.5,\n",
    "                        length_penalty=1.0,\n",
    "                        early_stopping=False\n",
    "                    )\n",
    "    output = tokenizer2.decode(summary_ids[0], skip_special_tokens=True)\n",
    "    translated_outputs[model_name2].append(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1c8b746f-43f2-4bf5-ab39-39e9235072f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vinai/vinai-translate-en2vi-v2\n"
     ]
    }
   ],
   "source": [
    "print(model_name4)\n",
    "translated_outputs[model_name4] = []\n",
    "for englishtext in englishtexts:\n",
    "    input_ids = tokenizer4([englishtext], padding=True, return_tensors=\"pt\").to(device)\n",
    "    output_ids = model4.generate(\n",
    "            **input_ids,\n",
    "            decoder_start_token_id=tokenizer4.lang_code_to_id[\"vi_VN\"],\n",
    "            num_return_sequences=1,\n",
    "            num_beams=5,\n",
    "            early_stopping=True\n",
    "        )\n",
    "    vi_texts = tokenizer4.batch_decode(output_ids, skip_special_tokens=True)\n",
    "    translated_outputs[model_name4].append(vi_texts[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2147b4c-03ba-4516-b621-2f3c9a419cce",
   "metadata": {},
   "source": [
    "## Take the translations to vietnamese and have each of the models translate those back into English"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "eeda0a8b-5ed6-4ae1-bc25-1f235d91c49d",
   "metadata": {},
   "outputs": [],
   "source": [
    "vietnamese_translations = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d87bb74f-ff01-4d98-ab38-08b92ec0d408",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NlpHUST/t5-vi-en-small\n"
     ]
    }
   ],
   "source": [
    "print(model_name3)\n",
    "vietnamese_translations[model_name3] = {}\n",
    "for key in translated_outputs:\n",
    "    vietnamese_translations[model_name3][key] = []\n",
    "    for input_text in translated_outputs[key]:\n",
    "        tokenized_text = tokenizer3.encode(input_text, return_tensors=\"pt\").to(device)\n",
    "        model3.eval()\n",
    "        summary_ids = model3.generate(\n",
    "                        tokenized_text,\n",
    "                        max_length=256,\n",
    "                        num_beams=5,\n",
    "                        repetition_penalty=2.5,\n",
    "                        length_penalty=1.0,\n",
    "                        early_stopping=False\n",
    "                    )\n",
    "        output2 = tokenizer3.decode(summary_ids[0], skip_special_tokens=True)\n",
    "        vietnamese_translations[model_name3][key].append(output2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9ae88478-a978-47c3-bc0c-183ef4043e00",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VietAI/envit5-translation\n"
     ]
    }
   ],
   "source": [
    "print(model_name)\n",
    "vietnamese_translations[model_name] = {}\n",
    "for key in translated_outputs:\n",
    "    vietnamese_translations[model_name][key] = []\n",
    "    for input_text in translated_outputs[key]:\n",
    "        outputs = model.generate(tokenizer([f'vi: {input_text}'], return_tensors=\"pt\", padding=True).input_ids.to(device), max_length=512)\n",
    "        test = [output for output in tokenizer.batch_decode(outputs, skip_special_tokens=True)][0].split('en: ')[1]\n",
    "        vietnamese_translations[model_name][key].append(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "86c68d7c-2398-4793-8697-718504626d9b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vinai/vinai-translate-vi2en-v2\n"
     ]
    }
   ],
   "source": [
    "print(model_name5)\n",
    "vietnamese_translations[model_name5] = {}\n",
    "for key in translated_outputs:\n",
    "    vietnamese_translations[model_name5][key] = []\n",
    "    for input_text in translated_outputs[key]:\n",
    "        input_ids = tokenizer5([input_text], padding=True, return_tensors=\"pt\").to(device)\n",
    "        output_ids = model5.generate(\n",
    "            **input_ids,\n",
    "            decoder_start_token_id=tokenizer5.lang_code_to_id[\"en_XX\"],\n",
    "            num_return_sequences=1,\n",
    "            num_beams=5,\n",
    "            early_stopping=False\n",
    "        )\n",
    "        en_texts = tokenizer5.batch_decode(output_ids, skip_special_tokens=True)\n",
    "        vietnamese_translations[model_name5][key].append(en_texts[0])\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8103f4b5-e055-4bd0-8021-734b022edc4e",
   "metadata": {},
   "source": [
    "## Dump all the results to json in data directory so can use the data later"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7ab295be-e66d-4a6a-9e60-fd47ada5a7f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from json import dump, load\n",
    "data = {\"original\":englishtexts, \"vietnamese\":translated_outputs, \"english\":vietnamese_translations, \"mappings\":{model_name:model_name,model_name3:model_name2,model_name5:model_name4}}\n",
    "data_path = \"data/translations.json\"\n",
    "with open(data_path,\"w\") as outfile:\n",
    "    dump(data,outfile,indent=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a39b20b4-0ab5-4122-993c-fea489e1931a",
   "metadata": {},
   "source": [
    "## Create an html document with a table of all the translations for analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ae3ab233-145e-4f44-be5f-cf473b3012bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from string import Template\n",
    "html_template = Template(\"<html><header><title>$title</title></header><body>$body</body></html>\")\n",
    "table_template = Template(\"<table><th>en2vi model</th><th>original</th><th>vi translation</th><th>$model1</th><th>$model2</th><th>$model3</th>$rows</table>\")\n",
    "vien_models = [x for x in data['vietnamese'].keys()]\n",
    "row_template = Template(\"<tr><td><b>$en2vi</b></td><td>$original</td><td>$translation</td><td>$v1</td><td>$v2</td><td>$v3</td></tr>\")\n",
    "rows = ''\n",
    "for key in data['english']:\n",
    "    for ndx in range(len(data[\"original\"])):\n",
    "        original = data[\"original\"][ndx]\n",
    "        translation = data[\"vietnamese\"][data[\"mappings\"][key]][ndx]\n",
    "        model1 = data[\"english\"][key][vien_models[0]][ndx]\n",
    "        model2 = data[\"english\"][key][vien_models[1]][ndx]\n",
    "        model3 = data[\"english\"][key][vien_models[2]][ndx]\n",
    "        row = row_template.substitute(en2vi=key,original=original,translation=translation,v1=model1,v2=model2,v3=model3)\n",
    "        rows += row\n",
    "body = table_template.substitute(model1=vien_models[0],model2=vien_models[1],model3=vien_models[2],rows=rows)\n",
    "html = html_template.substitute(title=\"Evaluate\",body=body)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1ffb837-e52c-4829-83bb-173fe66d9b83",
   "metadata": {},
   "source": [
    "## Have to write the string to file in utf-8 format, currently it is utf-16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2fee76cf-d9cf-4e8f-a374-d68f1b9644c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import codecs\n",
    "data_path = \"data/index.html\"\n",
    "with codecs.open(data_path,\"w\",'utf-8') as outfile:\n",
    "    outfile.write(html)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
